# Things I've Used in this Project

- Speech-Recognition for Microphone recording
- OpenAI's Whisper for Audio to Text
- Ollama for using Llama3's LLM
- TTS for text to speech
- vlc-python for audio playback
- WebSockets to communicate between server and client in real time

I use an edited version of Llama3, using the 'W-model' model file. Make sure it's installed. (ollama W -f W-model)

## Some key things

- Make sure you install the depenencies on the requirements text file. (python install -r requirements.txt)
- Make sure you have ffmpeg installed and put in your PATH ENV
- Models will automatically download so no need to manually do that.

### Changelog

- (8/10/2024)

> Web app should show messages quicker
> Some refactoring (okay a lot was made)

- (6/7/2024)

> Refactored 'processing.py'
